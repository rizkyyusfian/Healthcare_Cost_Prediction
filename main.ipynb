{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_900 = pd.read_csv('dataset/medical900.csv')\n",
    "df_1300 = pd.read_csv('dataset/medical1300.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1300.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((986, 11), (1338, 7))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_900.shape, df_1300.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error (MAE): 2732.7675242187497\n",
      "Root Mean Squared Error (RMSE): 2732.7675242187497\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.pipeline import Pipeline\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# # Sample DataFrame\n",
    "# data = pd.DataFrame({\n",
    "#     'age': [19, 18, 28, 33, 32],\n",
    "#     'sex': ['female', 'male', 'male', 'male', 'male'],\n",
    "#     'bmi': [27.9, 33.77, 33.0, 22.705, 28.88],\n",
    "#     'children': [0, 1, 3, 0, 0],\n",
    "#     'smoker': ['yes', 'no', 'no', 'no', 'no'],\n",
    "#     'region': ['southwest', 'southeast', 'southeast', 'northwest', 'northwest'],\n",
    "#     'charges': [16884.924, 1725.5523, 4449.462, 21984.47061, 3866.8552]\n",
    "# })\n",
    "\n",
    "# # Separate features and target\n",
    "# X = data.drop('charges', axis=1)\n",
    "# y = data['charges']\n",
    "\n",
    "# # Identify categorical columns\n",
    "# categorical_cols = ['sex', 'smoker', 'region']\n",
    "\n",
    "# # Define the ColumnTransformer with OneHotEncoder for categorical columns\n",
    "# preprocessor = ColumnTransformer(\n",
    "#     transformers=[\n",
    "#         ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "#     ],\n",
    "#     remainder='passthrough'  # Keep other columns as they are\n",
    "# )\n",
    "\n",
    "# # Define the pipeline\n",
    "# pipeline = Pipeline(steps=[\n",
    "#     ('preprocessor', preprocessor),\n",
    "#     ('model', xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, learning_rate=0.1, max_depth=5))\n",
    "# ])\n",
    "\n",
    "# # Split the data into training and testing sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train the model\n",
    "# pipeline.fit(X_train, y_train)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# # Evaluate the model\n",
    "# mae = mean_absolute_error(y_test, y_pred)\n",
    "# rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "\n",
    "# print(f\"Mean Absolute Error (MAE): {mae}\")\n",
    "# print(f\"Root Mean Squared Error (RMSE): {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "Best parameters for XGB: {'model__subsample': 0.9, 'model__n_estimators': 100, 'model__max_depth': 3, 'model__learning_rate': 0.046415888336127774, 'model__colsample_bytree': 0.8}\n",
      "Best parameters for RF: {'model__n_estimators': 300, 'model__min_samples_split': 2, 'model__min_samples_leaf': 2, 'model__max_depth': 3, 'model__bootstrap': True}\n",
      "Best parameters for GB: {'model__subsample': 0.6, 'model__n_estimators': 250, 'model__max_depth': 3, 'model__learning_rate': 0.01}\n",
      "Mean Absolute Error (MAE) for XGB: 2286.0895941911144\n",
      "Root Mean Squared Error (RMSE) for XGB: 4036.520034448741\n",
      "Mean Absolute Error (MAE) for RF: 2281.260385364732\n",
      "Root Mean Squared Error (RMSE) for RF: 4109.312165684919\n",
      "Mean Absolute Error (MAE) for GB: 2651.4728697998285\n",
      "Root Mean Squared Error (RMSE) for GB: 4196.074184386716\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold, RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Sample DataFrame\n",
    "data = df_1300.copy()\n",
    "\n",
    "# Separate features and target\n",
    "X = data.drop('charges', axis=1)\n",
    "y = data['charges']\n",
    "\n",
    "# Identify categorical columns\n",
    "categorical_cols = ['sex', 'smoker', 'region']\n",
    "numerical_cols = ['age', 'bmi', 'children']\n",
    "\n",
    "# Handle Outliers\n",
    "# For simplicity, let's use the IQR method to identify outliers in 'charges' and cap them\n",
    "Q1 = data['charges'].quantile(0.25)\n",
    "Q3 = data['charges'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "data['charges'] = np.where(data['charges'] < lower_bound, lower_bound, data['charges'])\n",
    "data['charges'] = np.where(data['charges'] > upper_bound, upper_bound, data['charges'])\n",
    "\n",
    "# Re-separate features and target after outlier handling\n",
    "X = data.drop('charges', axis=1)\n",
    "y = data['charges']\n",
    "\n",
    "# Feature Engineering: Polynomial Features for numerical data\n",
    "polynomial_transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "# Define the ColumnTransformer with OneHotEncoder for categorical columns and StandardScaler for numerical columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', polynomial_transformer, numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep other columns as they are\n",
    ")\n",
    "\n",
    "# Model Pipelines\n",
    "pipeline_xgb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', xgb.XGBRegressor(objective='reg:squarederror'))\n",
    "])\n",
    "\n",
    "pipeline_rf = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "pipeline_gb = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', GradientBoostingRegressor())\n",
    "])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "param_distributions_xgb = {\n",
    "    'model__n_estimators': np.arange(50, 301, 50),\n",
    "    'model__learning_rate': np.logspace(-3, 0, 10),\n",
    "    'model__max_depth': np.arange(3, 10, 1),\n",
    "    'model__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "    'model__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "param_distributions_rf = {\n",
    "    'model__n_estimators': np.arange(50, 301, 50),\n",
    "    'model__max_depth': np.arange(3, 20, 2),\n",
    "    'model__min_samples_split': [2, 5, 10],\n",
    "    'model__min_samples_leaf': [1, 2, 4],\n",
    "    'model__bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "param_distributions_gb = {\n",
    "    'model__n_estimators': np.arange(50, 301, 50),\n",
    "    'model__learning_rate': np.logspace(-3, 0, 10),\n",
    "    'model__max_depth': np.arange(3, 10, 1),\n",
    "    'model__subsample': [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Randomized search for hyperparameter tuning\n",
    "random_search_xgb = RandomizedSearchCV(estimator=pipeline_xgb, param_distributions=param_distributions_xgb, n_iter=100, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=42)\n",
    "random_search_rf = RandomizedSearchCV(estimator=pipeline_rf, param_distributions=param_distributions_rf, n_iter=100, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=42)\n",
    "random_search_gb = RandomizedSearchCV(estimator=pipeline_gb, param_distributions=param_distributions_gb, n_iter=100, cv=3, scoring='neg_mean_squared_error', verbose=1, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Fit the random search to the data\n",
    "random_search_xgb.fit(X_train, y_train)\n",
    "random_search_rf.fit(X_train, y_train)\n",
    "random_search_gb.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters\n",
    "best_params_xgb = random_search_xgb.best_params_\n",
    "best_params_rf = random_search_rf.best_params_\n",
    "best_params_gb = random_search_gb.best_params_\n",
    "\n",
    "print(f\"Best parameters for XGB: {best_params_xgb}\")\n",
    "print(f\"Best parameters for RF: {best_params_rf}\")\n",
    "print(f\"Best parameters for GB: {best_params_gb}\")\n",
    "\n",
    "# Use the best models\n",
    "best_model_xgb = random_search_xgb.best_estimator_\n",
    "best_model_rf = random_search_rf.best_estimator_\n",
    "best_model_gb = random_search_gb.best_estimator_\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = best_model_xgb.predict(X_test)\n",
    "y_pred_rf = best_model_rf.predict(X_test)\n",
    "y_pred_gb = best_model_gb.predict(X_test)\n",
    "\n",
    "# Evaluate the best models\n",
    "mae_xgb = mean_absolute_error(y_test, y_pred_xgb)\n",
    "rmse_xgb = mean_squared_error(y_test, y_pred_xgb, squared=False)\n",
    "\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "rmse_rf = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "rmse_gb = mean_squared_error(y_test, y_pred_gb, squared=False)\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for XGB: {mae_xgb}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) for XGB: {rmse_xgb}\")\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for RF: {mae_rf}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) for RF: {rmse_rf}\")\n",
    "\n",
    "print(f\"Mean Absolute Error (MAE) for GB: {mae_gb}\")\n",
    "print(f\"Root Mean Squared Error (RMSE) for GB: {rmse_gb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Mean Absolute Error (MAE): 8454.806521277427\n",
      "Baseline Root Mean Squared Error (RMSE): 10428.199030100852\n"
     ]
    }
   ],
   "source": [
    "# Baseline model: Mean Predictor\n",
    "y_mean_pred = np.mean(y_train)\n",
    "\n",
    "# Calculate MAE and RMSE for the baseline model\n",
    "baseline_mae = mean_absolute_error(y_test, [y_mean_pred] * len(y_test))\n",
    "baseline_rmse = mean_squared_error(y_test, [y_mean_pred] * len(y_test), squared=False)\n",
    "\n",
    "print(f\"Baseline Mean Absolute Error (MAE): {baseline_mae}\")\n",
    "print(f\"Baseline Root Mean Squared Error (RMSE): {baseline_rmse}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
